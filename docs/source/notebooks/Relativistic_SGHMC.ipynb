{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relativistic SGHMC \"Relativistic Monte Carlo\"\n",
    "\n",
    "In this notebook we reproduce the results of the paper \n",
    "[Relativistic Monte Carlo](http://proceedings.mlr.press/v54/lu17b/lu17b.pdf#page=7).\n",
    "\n",
    "We start by introducing and plotting all relevant log likelihoods of our objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(\".\"), \"..\", \"..\", \"..\"))\n",
    "\n",
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "from pymc3.backends.base import MultiTrace\n",
    "from pymc3.diagnostics import effective_n as ess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pysgmcmc.samplers.relativistic_sghmc import RelativisticSGHMCSampler\n",
    "\n",
    "from pysgmcmc.diagnostics.objective_functions import (\n",
    "    banana_log_likelihood,\n",
    "    gmm1_log_likelihood, gmm2_log_likelihood,\n",
    "    gmm3_log_likelihood\n",
    ")\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "ObjectiveFunction = namedtuple(\n",
    "    \"ObjectiveFunction\", [\"function\", \"dimensionality\"]\n",
    ")\n",
    "\n",
    "objective_functions = (\n",
    "    ObjectiveFunction(\n",
    "        function=banana_log_likelihood, dimensionality=2\n",
    "    ),\n",
    "    ObjectiveFunction(\n",
    "        function=gmm1_log_likelihood, dimensionality=1\n",
    "    ),\n",
    "    ObjectiveFunction(\n",
    "        function=gmm2_log_likelihood, dimensionality=1\n",
    "    ),\n",
    "    ObjectiveFunction(\n",
    "        function=gmm3_log_likelihood, dimensionality=1\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def cost_function(log_likelihood_function):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return -log_likelihood_function(*args, **kwargs)\n",
    "    wrapped.__name__ = log_likelihood_function.__name__\n",
    "    return wrapped\n",
    "\n",
    "#  Banana Contour {{{ #\n",
    "def banana_plot():\n",
    "    #x = np.arange(-30, 30, 0.05)\n",
    "    #y = np.arange(-60, 20, 0.05)\n",
    "    x = np.arange(-25, 25, 0.05)\n",
    "    y = np.arange(-50, 20, 0.05)\n",
    "    xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "    densities = np.asarray([np.exp(banana_log_likelihood((x, y))) for x in xx for y in yy])\n",
    "    f, ax = plt.subplots(1)\n",
    "    xdata = [1, 4, 8]\n",
    "    ydata = [10, 20, 30]\n",
    "    ax.contour(x, y, densities, 1, label=\"Banana\")\n",
    "    ax.plot([], [], label=\"Banana\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    #ax.set_ylim(ymin=-10, ymax=40)\n",
    "    #ax.set_xlim(xmin=-6, xmax=7)\n",
    "    ax.set_ylim(ymin=-60, ymax=20)\n",
    "    ax.set_xlim(xmin=-30, xmax=30)\n",
    "    \n",
    "#  }}} Banana Contour #\n",
    "\n",
    "#  Gaussian Mixture Models {{{ #\n",
    "\n",
    "def gmm_plot(gmm_fun, label=None):\n",
    "    xv = np.arange(-10, 10, 0.1)\n",
    "    yv = np.asarray([np.exp(gmm_fun(xi)) for xi in xv])\n",
    "    plt.grid()\n",
    "    plt.plot(xv, yv, label=label)\n",
    "    plt.legend()\n",
    "\n",
    "plot_functions = {\n",
    "    \"banana_log_likelihood\": banana_plot,\n",
    "    \"gmm1_log_likelihood\": lambda: gmm_plot(gmm1_log_likelihood, label=\"GMM_1\"),\n",
    "    \"gmm2_log_likelihood\": lambda: gmm_plot(gmm2_log_likelihood, label=\"GMM_2\"),\n",
    "    \"gmm3_log_likelihood\": lambda: gmm_plot(gmm3_log_likelihood, label=\"GMM_3\"),\n",
    "}\n",
    "\n",
    "\n",
    "def extract_samples(sampler, n_samples=1000, keep_every=10):\n",
    "    from itertools import islice\n",
    "    n_iterations = n_samples * keep_every\n",
    "    return np.asarray(\n",
    "        [sample for sample, _ in\n",
    "         islice(sampler, 0, n_iterations, keep_every)]\n",
    "    )\n",
    "\n",
    "def plot_samples(sampler, n_samples=1000, keep_every=10):\n",
    "    samples = extract_samples(\n",
    "        sampler, n_samples=n_samples, keep_every=keep_every\n",
    "    )\n",
    "    plot_functions[sampler.cost_fun.__name__]()\n",
    "    \n",
    "    first_sample = samples[0]\n",
    "    try:\n",
    "        sample_dimensionality, = first_sample.shape\n",
    "    except ValueError:\n",
    "        plt.scatter(samples, np.exp([-sampler.cost_fun(sample) for sample in samples]))\n",
    "    else:\n",
    "        plt.scatter(*[samples[:, i] for i in range(sample_dimensionality)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract samples and plot them\n",
    "\n",
    "Below we extract $1000$ samples for each cost function using relativistic sghmc and plot the samples on top of the respective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pysgmcmc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eb6cd9f04563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpysgmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelativistic_sghmc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRelativisticSGHMCSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpysgmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepsize_schedules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantStepsizeSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensionality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjective_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pysgmcmc'"
     ]
    }
   ],
   "source": [
    "from pysgmcmc.samplers.relativistic_sghmc import RelativisticSGHMCSampler\n",
    "from pysgmcmc.stepsize_schedules import ConstantStepsizeSchedule\n",
    "\n",
    "for function, dimensionality in objective_functions:\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        if function.__name__ == \"banana_log_likelihood\":\n",
    "            params = [\n",
    "                tf.Variable(0., dtype=tf.float32, name=\"x\"), \n",
    "                tf.Variable(6., dtype=tf.float32, name=\"y\")\n",
    "            ]\n",
    "        else:\n",
    "            params = [tf.Variable(0., dtype=tf.float32, name=\"x\")]\n",
    "        sampler = RelativisticSGHMCSampler(\n",
    "            stepsize_schedule=ConstantStepsizeSchedule(0.1),\n",
    "            params=params, \n",
    "            cost_fun=cost_function(function), \n",
    "            session=session,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        session.run(tf.global_variables_initializer())\n",
    "    \n",
    "        plot_samples(sampler)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics\n",
    "\n",
    "Next, we analyze some diagnostics of our relativistic sghmc sampler. Namely, we will study how effective sample sizes (ESS) and mean absolute error (MAE) behave and vary over different values for the stepsize $\\epsilon$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
