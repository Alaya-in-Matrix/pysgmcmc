{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(\"..\", \"..\", \"..\")))\n",
    "import pysgmcmc as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating a Sampler\n",
    "\n",
    "To instantiate a sampler, we need two ingredients:\n",
    "\n",
    "1. Target parameters of the sampler: a list of `tensorflow.Variable` objects \n",
    "2. A cost function: callable that maps these target parameters to a 1-d `tensorflow.Tensor` representing their corresponding costs\n",
    "\n",
    "Note: In MCMC literature, the target parameters are often denoted as $\\theta$ and the cost function is frequently referred to as $U(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target parameters\n",
    "parameters = [tf.Variable(0.), tf.Variable(0.)]\n",
    "\n",
    "# cost function\n",
    "def banana_nll(params):\n",
    "    x, y = params\n",
    "    return -1./2. * (x ** 2 / 100. + (y + 0.1 * x ** 2 -10) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these ingredients, we can instantiate any of our samplers within a `tensorflow.Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "sampler = SGHMCSampler(\n",
    "    params=parameters, cost_fun=banana_nll, session=session, dtype=tf.float32\n",
    ")\n",
    "\n",
    "session.run(tf.global_variables_initializer())  # initialize variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data minibatches\n",
    "\n",
    "A major motivation to use Stochastic Gradient MCMC methods is that they leverage MCMC methods\n",
    "to large datasets by *subsampling* them. \n",
    "\n",
    "To this end, our samplers take an iterable *batch_generator* as input and use it to repeatedly subsample the dataset.\n",
    "\n",
    "We provide two simple default ways to generate batches, which can be found in module \n",
    "[pysgmcmc.data_batches](http://pysgmcmc.readthedocs.io/en/latest/api/data_batches.html). \n",
    "You can easily add your own custom batch generation facilities, e.g. by writing a (infinite) generator function that *yields* a dictionary mapping two placeholders for the data to batches of data (usually *np.array*s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "from pysgmcmc.data_batches import generate_batches\n",
    "\n",
    "session = tf.Session()\n",
    "params = [tf.Variable(0., dtype=tf.float64)]\n",
    "\n",
    "def sinc(x):\n",
    "    import numpy as np\n",
    "    return np.sinc(x * 10 - 5).sum(axis=1)\n",
    "\n",
    "# XXX: Use cost function from BNN Negloglikelihood here?\n",
    "# Then, we can even show a batch and run a single iteration \n",
    "dummy_costs = lambda params: tf.reduce_sum(params)  # dummy cost function; ignore this it is not used\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y = sinc(X)\n",
    "\n",
    "x_placeholder, y_placeholder = tf.placeholder(dtype=tf.float64), tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "## Batch Generator (uniform random subsampling) ##\n",
    "batch_generator = generate_batches(X, y, x_placeholder, y_placeholder, batch_size=20)\n",
    "\n",
    "batched_sampler = SGHMCSampler(\n",
    "    params=params, cost_fun=dummy_costs, session=session,\n",
    "    batch_generator=batch_generator  # Pass the iterable into our sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All calls to \n",
    "```python \n",
    "next(batched_sampler)\n",
    "``` \n",
    "will use batches obtained by calling `next(batch_generator)`\n",
    "when computing the costs for the current iteration.\n",
    "\n",
    "Note: the cost function (`cost_fun`) passed to the sampler must use the placeholders passed to `generate_batches`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available samplers\n",
    "\n",
    "To get an overview of which samplers are available for use, examine our [documentation](http://pysgmcmc.readthedocs.io/en/latest/) or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysgmcmc.samplers in pysgmcmc:\n",
      "\n",
      "NAME\n",
      "    pysgmcmc.samplers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    relativistic_hmc\n",
      "    relativistic_hmc2\n",
      "    relativistic_sghmc\n",
      "    sghmc\n",
      "    sgld\n",
      "    svgd\n",
      "\n",
      "CLASSES\n",
      "    pysgmcmc.sampling.BurnInMCMCSampler(pysgmcmc.sampling.MCMCSampler)\n",
      "        pysgmcmc.samplers.sghmc.SGHMCSampler\n",
      "        pysgmcmc.samplers.sgld.SGLDSampler\n",
      "    \n",
      "    class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      "     |      Stochastic Gradient Hamiltonian Monte Carlo\n",
      "     |      In Proceedings of Machine Learning Research 32 (2014).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGHMCSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, mdecay=0.05)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |          Defaults to `1.0` which corresponds to no scaling.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      mdecay : float, optional\n",
      "     |          (Constant) momentum decay per time-step.\n",
      "     |          Defaults to `0.05`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Simple, plain example:\n",
      "     |      TODO: Add 2D Gaussian Case here\n",
      "     |      \n",
      "     |      Simple example that uses batches:\n",
      "     |      TODO: Add simplified batch example here\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SGLDSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Langevin Dynamics Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Langevin Dynamics.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |  [2] M.Welling, Y. W. Teh\n",
      "     |      Bayesian Learning via Stochastic Gradient Langevin Dynamics\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGLDSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, A=1.0)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |      \n",
      "     |      A : float, optional\n",
      "     |          TODO XXX Doku\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Simple, plain example:\n",
      "     |      TODO: Add more samples\n",
      "     |      \n",
      "     |      Simple example that uses batches:\n",
      "     |      TODO: Add simplified batch example here\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      tensorflow_mcmc.sampling.mcmc_base_classes.BurnInMCMCSampler:\n",
      "     |          Base class for `SGLDSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['SGHMCSampler', 'SGLDSampler']\n",
      "\n",
      "FILE\n",
      "    /mhome/freidanm/repos/pysgmcmc/pysgmcmc/samplers/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampler hyperparameters\n",
    "\n",
    "To get a clearer picture of all possible design choices when instantiating any of \n",
    "our samplers, consider our docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGHMCSampler in module pysgmcmc.samplers.sghmc:\n",
      "\n",
      "class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      " |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      " |  procedure to adapt its own hyperparameters during the initial stages\n",
      " |  of sampling.\n",
      " |  \n",
      " |  See [1] for more details on this burn-in procedure.\n",
      " |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      " |  \n",
      " |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      " |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      " |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      " |  \n",
      " |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      " |      Stochastic Gradient Hamiltonian Monte Carlo\n",
      " |      In Proceedings of Machine Learning Research 32 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGHMCSampler\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      " |      pysgmcmc.sampling.MCMCSampler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, mdecay=0.05)\n",
      " |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      " |          for later queries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : list of tensorflow.Variable objects\n",
      " |          Target parameters for which we want to sample new values.\n",
      " |      \n",
      " |      cost_fun : callable\n",
      " |          Function that takes `params` as input and returns a\n",
      " |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      " |          Frequently denoted with `U` in literature.\n",
      " |      \n",
      " |      seed : int, optional\n",
      " |          Random seed to use.\n",
      " |          Defaults to `None`.\n",
      " |      \n",
      " |      batch_generator : iterable, optional\n",
      " |          Iterable which returns dictionaries to feed into\n",
      " |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      " |          Defaults to `None` which indicates that no batches shall be fed.\n",
      " |      \n",
      " |      epsilon : float, optional\n",
      " |          Value that is used as learning rate parameter for the sampler,\n",
      " |          also denoted as discretization parameter in literature.\n",
      " |          Defaults to `0.01`.\n",
      " |      \n",
      " |      session : tensorflow.Session, optional\n",
      " |          Session object which knows about the external part of the graph\n",
      " |          (which defines `Cost`, and possibly batches).\n",
      " |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      " |      \n",
      " |      burn_in_steps: int, optional\n",
      " |          Number of burn-in steps to perform. In each burn-in step, this\n",
      " |          sampler will adapt its own internal parameters to decrease its error.\n",
      " |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      " |      \n",
      " |      scale_grad : float, optional\n",
      " |          Value that is used to scale the magnitude of the noise used\n",
      " |          during sampling. In a typical batches-of-data setting this usually\n",
      " |          corresponds to the number of examples in the entire dataset.\n",
      " |          Defaults to `1.0` which corresponds to no scaling.\n",
      " |      \n",
      " |      dtype : tensorflow.DType, optional\n",
      " |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      " |          Defaults to `tensorflow.float64`.\n",
      " |      \n",
      " |      mdecay : float, optional\n",
      " |          (Constant) momentum decay per time-step.\n",
      " |          Defaults to `0.05`.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Simple, plain example:\n",
      " |      TODO: Add 2D Gaussian Case here\n",
      " |      \n",
      " |      Simple example that uses batches:\n",
      " |      TODO: Add simplified batch example here\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      " |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __next__(self)\n",
      " |      Perform a sampler step:\n",
      " |          Compute and return the next sample and next cost values\n",
      " |          for this sampler.\n",
      " |      \n",
      " |          While `self.is_burning_in` returns `True`\n",
      " |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      " |          steps) this will also adapt the samplers mass matrix in a\n",
      " |          sampler-specific way to improve performance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sample: list of numpy.ndarray objects\n",
      " |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      " |      \n",
      " |      cost: numpy.ndarray (1,)\n",
      " |          Current cost value of the last evaluated target parameter values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  is_burning_in\n",
      " |      Check if this sampler is still in burn-in phase.\n",
      " |          Used during graph construction to insert conditionals into the\n",
      " |          graph that will make the sampler skip all burn-in operations\n",
      " |          after the burn-in phase is over.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_burning_in: boolean\n",
      " |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows using samplers as iterators.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Extract the first three thousand samples (with costs) from a sampler:\n",
      " |      \n",
      " |      >>> import tensorflow as tf\n",
      " |      >>> import numpy as np\n",
      " |      >>> from itertools import islice\n",
      " |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      " |      >>> session = tf.Session()\n",
      " |      >>> x = tf.Variable(1.0)\n",
      " |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      " |      >>> n_burn_in, n_samples = 1000, 2000\n",
      " |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      " |      >>> session.run(tf.global_variables_initializer())\n",
      " |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      " |      >>> samples = list(islice(sampler, n_samples))\n",
      " |      >>> len(burn_in_samples), len(samples)\n",
      " |      (1000, 2000)\n",
      " |      >>> session.close()\n",
      " |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers.SGHMCSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting samples\n",
    "\n",
    "Extracting the next sample (with corresponding costs) from any of our samplers always simply amounts to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.00041885159, -0.0035394728], -50.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, cost = next(sampler)\n",
    "\n",
    "sample, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This interface allows us to extract samples in different contexts:\n",
    "\n",
    "1. extract a chain of n subsequent samples\n",
    "2. sample until an external event occurs / an external condition becomes `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. extract a chain of n subsequent samples\n",
    "samples, n = [], 1000\n",
    "\n",
    "\n",
    "for _ in range(n):\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "\n",
    "# shorthand for 1., using itertools.islice\n",
    "import itertools\n",
    "samples = [sample for sample, _ in itertools.islice(sampler, n)]\n",
    "    \n",
    "# 2. sample until an external event occurs\n",
    "\n",
    "# dummy event\n",
    "def external_event():\n",
    "    return np.random.randint(0, 10) > 5\n",
    "\n",
    "samples = []\n",
    "while not external_event():\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "    \n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also allows us to use any of our samplers in (infinite) for-loops. \n",
    "\n",
    "But *be warned*: such a for-loop will **not terminate** unless you explicitly break out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples, i = [], 0\n",
    "for sample, cost in sampler:\n",
    "    if i > 10:\n",
    "        break  # we need to explicitly *break* out of the loop\n",
    "    i += 1\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing chains/traces of samples\n",
    "\n",
    "To analyze the results of a sampler run, we transform the results obtained by our samplers into `pymc3.MultiTrace` objects. Then we can use the (well-established) `pymc3` machinery to compute diagnostics for our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "\n",
    "# XXX: Compute PYSGMCMCTrace (and possibly pymc3.MultiTrace from those) and \n",
    "# use those to compute e.g. ess and maybe produce some plots too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we also provide a shortcut function that directly computes a multitrace for one of our samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pymc3_multitrace in module pysgmcmc.diagnostics.sample_chains:\n",
      "\n",
      "pymc3_multitrace(get_sampler, n_chains=2, samples_per_chain=100, parameter_names=None)\n",
      "    Extract chains from `sampler` and return them as `pymc3.MultiTrace`\n",
      "        object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    get_sampler : callable\n",
      "        A callable that takes a `tensorflow.Session` object as input\n",
      "        and returns a (possibly already burnt-in) instance of a\n",
      "        `pysgmcmc.sampling.MCMCSampler` subclass.\n",
      "    \n",
      "    parameter_names : List[String] or NoneType, optional\n",
      "        List of names for each target parameter of the sampler.\n",
      "        If set to `None`, simply enumerate the parameters and use those numbers\n",
      "        as names.\n",
      "        Defaults to `None`.\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    multitrace : pymc3.backends.base.MultiTrace\n",
      "        TODO: DOKU\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    ----------\n",
      "    TODO ADD EXAMPLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.diagnostics.sample_chains.pymc3_multitrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PYSGMCMC - trained BNN\n",
    "\n",
    "We provide an implementation of a Bayesian Neural Network that is trained using our samplers. \n",
    "\n",
    "The (tensorflow-) architecture of this BNN can be customized by the user and any of our sampling methods can be used to sample networks during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIWQomn8IIWToP42MmBtIWlpCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a75df8e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pysgmcmc.diagnostics.objective_functions import sinc\n",
    "from pysgmcmc.models.bayesian_neural_network import BayesianNeuralNetwork, SamplingMethod\n",
    "\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X_train = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y_train = sinc(X_train)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)[:, None]\n",
    "y_test = sinc(X_test)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "session = tf.InteractiveSession(graph=g)\n",
    "with g.as_default():\n",
    "    model = BayesianNeuralNetwork(\n",
    "        session=session, batch_size=20, sampling_method=SamplingMethod.SGHMC,\n",
    "        learning_rate=np.sqrt(1e-4), mdecay=0.05, \n",
    "        burn_in_steps=3000, n_iters=50000, \n",
    "        normalize_input=True, normalize_output=True,\n",
    "    )\n",
    "    model.train(X_train, y_train)\n",
    "    prediction_mean, prediction_variance = model.predict(X_test)\n",
    "\n",
    "prediction_std = np.sqrt(prediction_variance)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(X_test[:, 0], y_test, label=\"true\", color=\"black\")\n",
    "plt.plot(X_train[:, 0], y_train, \"ro\")\n",
    "\n",
    "plt.plot(X_test[:, 0], prediction_mean, label=\"SGHMC\", color=\"blue\")\n",
    "plt.fill_between(X_test[:, 0], prediction_mean + prediction_std, prediction_mean - prediction_std, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
