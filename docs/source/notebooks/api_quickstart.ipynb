{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(\"..\", \"..\", \"..\")))\n",
    "import pysgmcmc as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating a Sampler\n",
    "\n",
    "To instantiate a sampler, we need two ingredients:\n",
    "\n",
    "1. Target parameters of the sampler: a list of `tensorflow.Variable` objects \n",
    "2. A cost function: callable that maps these target parameters to a 1-d `tensorflow.Tensor` representing their corresponding costs\n",
    "\n",
    "Note: In MCMC literature, the target parameters are often denoted as $\\theta$.\n",
    "Our cost function corresponds to the negative of the log likelihood. The log likelihood is frequently referred to as $U(\\theta)$ in literature, so our cost function corresponds to $-U(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters\n",
    "parameters = [tf.Variable(0.), tf.Variable(0.)]\n",
    "\n",
    "# cost function\n",
    "def banana_nll(params):\n",
    "    x, y = params\n",
    "    return -1./2. * (x ** 2 / 100. + (y + 0.1 * x ** 2 -10) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these ingredients, we can instantiate any of our samplers within a `tensorflow.Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "sampler = SGHMCSampler(\n",
    "    params=parameters, cost_fun=banana_nll, session=session, dtype=tf.float32\n",
    ")\n",
    "\n",
    "session.run(tf.global_variables_initializer())  # initialize variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data minibatches\n",
    "\n",
    "A major motivation to use Stochastic Gradient MCMC methods is that they leverage MCMC methods\n",
    "to large datasets by *subsampling* them. \n",
    "\n",
    "To this end, our samplers take an iterable *batch_generator* as input and use it to repeatedly subsample the dataset.\n",
    "\n",
    "We provide two simple default ways to generate batches, which can be found in module \n",
    "[pysgmcmc.data_batches](http://pysgmcmc.readthedocs.io/en/latest/api/data_batches.html). \n",
    "You can easily add your own custom batch generation facilities, e.g. by writing a (infinite) generator function that *yields* a dictionary mapping two placeholders for the data to batches of data (usually *np.array*s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "from pysgmcmc.data_batches import generate_batches\n",
    "\n",
    "session = tf.Session()\n",
    "params = [tf.Variable(0., dtype=tf.float64)]\n",
    "\n",
    "def sinc(x):\n",
    "    import numpy as np\n",
    "    return np.sinc(x * 10 - 5).sum(axis=1)\n",
    "\n",
    "# XXX: Use cost function from BNN Negloglikelihood here?\n",
    "# Then, we can even show a batch and run a single iteration \n",
    "dummy_costs = lambda params: tf.reduce_sum(params)  # dummy cost function; ignore this it is not used\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y = sinc(X)\n",
    "\n",
    "x_placeholder, y_placeholder = tf.placeholder(dtype=tf.float64), tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "## Batch Generator (uniform random subsampling) ##\n",
    "batch_generator = generate_batches(X, y, x_placeholder, y_placeholder, batch_size=20)\n",
    "\n",
    "batched_sampler = SGHMCSampler(\n",
    "    params=params, cost_fun=dummy_costs, session=session,\n",
    "    batch_generator=batch_generator  # Pass the iterable into our sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All calls to \n",
    "```python \n",
    "next(batched_sampler)\n",
    "``` \n",
    "will use batches obtained by calling `next(batch_generator)`\n",
    "when computing the costs for the current iteration.\n",
    "\n",
    "Note: the cost function (`cost_fun`) passed to the sampler must use the placeholders passed to `generate_batches`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available samplers\n",
    "\n",
    "To get an overview of which samplers are available for use, examine our [documentation](http://pysgmcmc.readthedocs.io/en/latest/) or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysgmcmc.samplers in pysgmcmc:\n",
      "\n",
      "NAME\n",
      "    pysgmcmc.samplers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    relativistic_sghmc\n",
      "    sghmc\n",
      "    sgld\n",
      "\n",
      "CLASSES\n",
      "    pysgmcmc.sampling.BurnInMCMCSampler(pysgmcmc.sampling.MCMCSampler)\n",
      "        pysgmcmc.samplers.sghmc.SGHMCSampler\n",
      "        pysgmcmc.samplers.sgld.SGLDSampler\n",
      "    pysgmcmc.sampling.MCMCSampler(builtins.object)\n",
      "        pysgmcmc.samplers.relativistic_sghmc.RelativisticSGHMCSampler\n",
      "    \n",
      "    class RelativisticSGHMCSampler(pysgmcmc.sampling.MCMCSampler)\n",
      "     |  Relativistic Stochastic Gradient Hamiltonian Monte-Carlo Sampler.\n",
      "     |  \n",
      "     |          See [1] for more details on Relativistic SGHMC.\n",
      "     |          [1] X. Lu, V. Perrone, L. Hasenclever, Y. W. Teh, S. J. Vollmer\n",
      "     |              In Proceedings of the 20 th International Conference on Artifi-\n",
      "     |  cial Intelligence and Statistics (AISTATS) 2017\n",
      "     |  \n",
      "     |              `Relativistic Monte Carlo <proceedings.mlr.press/v54/lu17b/lu17b.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RelativisticSGHMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, momentum=[0.0], batch_generator=None, epsilon=0.001, mass=1.0, c=1.0, D=1.0, Bhat=0.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      Cost : tensorflow.Tensor\n",
      "     |          1-d Cost tensor that depends on `params`.\n",
      "     |          Frequently denoted as U(theta) in literature.\n",
      "     |      \n",
      "     |      momentum : float or List[float], optional\n",
      "     |          Initial values for the momentum of the sampler.\n",
      "     |          Defaults to `0.0`.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.001`.\n",
      "     |      \n",
      "     |      mass : float, optional\n",
      "     |          mass constant.\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      c : float, optional\n",
      "     |          \"Speed of light\" constant.\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      D : float, optional\n",
      "     |          Diffusion constant.\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      Bhat : float, optional\n",
      "     |          TODO: Documentation\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.MCMCSampler:\n",
      "     |          Base class for `RelativisticSGHMCSampler` that specifies how\n",
      "     |          actual sampling is performed (using iterator protocol,\n",
      "     |          e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  __next__(self, feed_vals=None)\n",
      "     |      Compute and return the next sample and\n",
      "     |          next cost values for this sampler.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Extract the next sample (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in = 1000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x:-dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> sample, cost = next(sampler)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "    \n",
      "    class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  \n",
      "     |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  \n",
      "     |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      "     |      In Proceedings of Machine Learning Research 32 (2014).\n",
      "     |  \n",
      "     |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGHMCSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      mdecay : float, optional\n",
      "     |          (Constant) momentum decay per time-step.\n",
      "     |          Defaults to `0.05`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |          Defaults to `1.0` which corresponds to no scaling.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_vals=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SGLDSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Langevin Dynamics Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Langevin Dynamics.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  [2] M.Welling, Y. W. Teh\n",
      "     |      In International Conference on Machine Learning (ICML) 28 (2011).\n",
      "     |  \n",
      "     |      `Bayesian Learning via Stochastic Gradient Langevin Dynamics. <https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGLDSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, A=1.0, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      A : float, optional\n",
      "     |          TODO Doku\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      tensorflow_mcmc.sampling.mcmc_base_classes.BurnInMCMCSampler:\n",
      "     |          Base class for `SGLDSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_vals=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['SGHMCSampler', 'RelativisticSGHMCSampler', 'SGLDSampler']\n",
      "\n",
      "FILE\n",
      "    /home/moritz/pysgmcmc/pysgmcmc/samplers/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampler hyperparameters\n",
    "\n",
    "To get a clearer picture of all possible design choices when instantiating any of \n",
    "our samplers, consider our docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGHMCSampler in module pysgmcmc.samplers.sghmc:\n",
      "\n",
      "class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      " |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      " |  procedure to adapt its own hyperparameters during the initial stages\n",
      " |  of sampling.\n",
      " |  \n",
      " |  See [1] for more details on this burn-in procedure.\n",
      " |  \n",
      " |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      " |  \n",
      " |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      " |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      " |  \n",
      " |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |  \n",
      " |  \n",
      " |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      " |      In Proceedings of Machine Learning Research 32 (2014).\n",
      " |  \n",
      " |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGHMCSampler\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      " |      pysgmcmc.sampling.MCMCSampler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      " |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      " |          for later queries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : list of tensorflow.Variable objects\n",
      " |          Target parameters for which we want to sample new values.\n",
      " |      \n",
      " |      cost_fun : callable\n",
      " |          Function that takes `params` as input and returns a\n",
      " |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      " |          Frequently denoted with `U` in literature.\n",
      " |      \n",
      " |      batch_generator : iterable, optional\n",
      " |          Iterable which returns dictionaries to feed into\n",
      " |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      " |          Defaults to `None` which indicates that no batches shall be fed.\n",
      " |      \n",
      " |      epsilon : float, optional\n",
      " |          Value that is used as learning rate parameter for the sampler,\n",
      " |          also denoted as discretization parameter in literature.\n",
      " |          Defaults to `0.01`.\n",
      " |      \n",
      " |      burn_in_steps: int, optional\n",
      " |          Number of burn-in steps to perform. In each burn-in step, this\n",
      " |          sampler will adapt its own internal parameters to decrease its error.\n",
      " |          Defaults to `3000`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      mdecay : float, optional\n",
      " |          (Constant) momentum decay per time-step.\n",
      " |          Defaults to `0.05`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      scale_grad : float, optional\n",
      " |          Value that is used to scale the magnitude of the noise used\n",
      " |          during sampling. In a typical batches-of-data setting this usually\n",
      " |          corresponds to the number of examples in the entire dataset.\n",
      " |          Defaults to `1.0` which corresponds to no scaling.\n",
      " |      \n",
      " |      session : tensorflow.Session, optional\n",
      " |          Session object which knows about the external part of the graph\n",
      " |          (which defines `Cost`, and possibly batches).\n",
      " |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      " |      \n",
      " |      dtype : tensorflow.DType, optional\n",
      " |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      " |          Defaults to `tensorflow.float64`.\n",
      " |      \n",
      " |      seed : int, optional\n",
      " |          Random seed to use.\n",
      " |          Defaults to `None`.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      " |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __next__(self, feed_vals=None)\n",
      " |      Perform a sampler step:\n",
      " |          Compute and return the next sample and next cost values\n",
      " |          for this sampler.\n",
      " |      \n",
      " |          While `self.is_burning_in` returns `True`\n",
      " |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      " |          steps) this will also adapt the samplers mass matrix in a\n",
      " |          sampler-specific way to improve performance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sample: list of numpy.ndarray objects\n",
      " |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      " |      \n",
      " |      cost: numpy.ndarray (1,)\n",
      " |          Current cost value of the last evaluated target parameter values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  is_burning_in\n",
      " |      Check if this sampler is still in burn-in phase.\n",
      " |          Used during graph construction to insert conditionals into the\n",
      " |          graph that will make the sampler skip all burn-in operations\n",
      " |          after the burn-in phase is over.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_burning_in: boolean\n",
      " |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows using samplers as iterators.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Extract the first three thousand samples (with costs) from a sampler:\n",
      " |      \n",
      " |      >>> import tensorflow as tf\n",
      " |      >>> import numpy as np\n",
      " |      >>> from itertools import islice\n",
      " |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      " |      >>> session = tf.Session()\n",
      " |      >>> x = tf.Variable(1.0)\n",
      " |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      " |      >>> n_burn_in, n_samples = 1000, 2000\n",
      " |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      " |      >>> session.run(tf.global_variables_initializer())\n",
      " |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      " |      >>> samples = list(islice(sampler, n_samples))\n",
      " |      >>> len(burn_in_samples), len(samples)\n",
      " |      (1000, 2000)\n",
      " |      >>> session.close()\n",
      " |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers.SGHMCSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting samples\n",
    "\n",
    "Extracting the next sample (with corresponding costs) from any of our samplers always simply amounts to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.00038432318, 0.0054607959], -50.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, cost = next(sampler)\n",
    "\n",
    "sample, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This interface allows us to extract samples in different contexts:\n",
    "\n",
    "1. extract a chain of n subsequent samples\n",
    "2. sample until an external event occurs / an external condition becomes `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.1384933, -4.2865024]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. extract a chain of n subsequent samples\n",
    "samples, n = [], 1000\n",
    "\n",
    "\n",
    "for _ in range(n):\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "\n",
    "# shorthand for 1., using itertools.islice\n",
    "import itertools\n",
    "samples = [sample for sample, _ in itertools.islice(sampler, n)]\n",
    "    \n",
    "# 2. sample until an external event occurs\n",
    "\n",
    "# dummy event\n",
    "def external_event():\n",
    "    return np.random.randint(0, 10) > 5\n",
    "\n",
    "samples = []\n",
    "while not external_event():\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "    \n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also allows us to use any of our samplers in (infinite) for-loops. \n",
    "\n",
    "But *be warned*: such a for-loop will **not terminate** unless you explicitly break out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples, i = [], 0\n",
    "for sample, cost in sampler:\n",
    "    if i > 10:\n",
    "        break  # we need to explicitly *break* out of the loop\n",
    "    i += 1\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing chains/traces of samples\n",
    "\n",
    "To analyze the results of a sampler run, we transform the results obtained by our samplers into `pymc3.MultiTrace` objects. Then we can use the (well-established) `pymc3` machinery to compute diagnostics for our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "\n",
    "# XXX: Compute PYSGMCMCTrace (and possibly pymc3.MultiTrace from those) and \n",
    "# use those to compute e.g. ess and maybe produce some plots too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we also provide a shortcut function that directly computes a multitrace for one of our samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pymc3_multitrace in module pysgmcmc.diagnostics.sample_chains:\n",
      "\n",
      "pymc3_multitrace(get_sampler, n_chains=2, samples_per_chain=100, parameter_names=None)\n",
      "    Extract chains from `sampler` and return them as `pymc3.MultiTrace` object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    get_sampler : callable\n",
      "        A callable that takes a `tensorflow.Session` object as input\n",
      "        and returns a (possibly already burnt-in) instance of a\n",
      "        `pysgmcmc.sampling.MCMCSampler` subclass.\n",
      "    \n",
      "    parameter_names : List[String] or NoneType, optional\n",
      "        List of names for each target parameter of the sampler.\n",
      "        If set to `None`, simply enumerate the parameters and use those numbers\n",
      "        as names.\n",
      "        Defaults to `None`.\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    multitrace : pymc3.backends.base.MultiTrace\n",
      "        TODO: DOKU\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    ----------\n",
      "    TODO ADD EXAMPLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.diagnostics.sample_chains.pymc3_multitrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PYSGMCMC - trained BNN\n",
    "\n",
    "We provide an implementation of a Bayesian Neural Network that is trained using our samplers. \n",
    "\n",
    "The (tensorflow-) architecture of this BNN can be customized by the user and any of our sampling methods can be used to sample networks during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80f8f51e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pysgmcmc.diagnostics.objective_functions import sinc\n",
    "from pysgmcmc.models.bayesian_neural_network import BayesianNeuralNetwork\n",
    "from pysgmcmc.sampling import Sampler\n",
    "\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X_train = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y_train = sinc(X_train)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)[:, None]\n",
    "y_test = sinc(X_test)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "session = tf.InteractiveSession(graph=g)\n",
    "with g.as_default():\n",
    "    model = BayesianNeuralNetwork(\n",
    "        session=session, batch_size=20, sampling_method=Sampler.SGHMC,\n",
    "        burn_in_steps=3000, n_iters=50000, \n",
    "        normalize_input=True, normalize_output=True,\n",
    "        learning_rate=np.sqrt(1e-4),\n",
    "        # sampler arguments for SGHMC\n",
    "        mdecay=0.05,         \n",
    "    )\n",
    "    model.train(X_train, y_train)\n",
    "    prediction_mean, prediction_variance = model.predict(X_test)\n",
    "\n",
    "prediction_std = np.sqrt(prediction_variance)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(X_test[:, 0], y_test, label=\"true\", color=\"black\")\n",
    "plt.plot(X_train[:, 0], y_train, \"ro\")\n",
    "\n",
    "plt.plot(X_test[:, 0], prediction_mean, label=\"SGHMC\", color=\"blue\")\n",
    "plt.fill_between(X_test[:, 0], prediction_mean + prediction_std, prediction_mean - prediction_std, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
