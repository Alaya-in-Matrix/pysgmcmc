{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(\"..\", \"..\", \"..\")))\n",
    "import pysgmcmc as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating a Sampler\n",
    "\n",
    "To instantiate a sampler, we need two ingredients:\n",
    "\n",
    "1. Target parameters of the sampler: a list of `tensorflow.Variable` objects \n",
    "2. A cost function: callable that maps these target parameters to a 1-d `tensorflow.Tensor` representing their corresponding costs\n",
    "\n",
    "Note: In MCMC literature, the target parameters are often denoted as $\\theta$.\n",
    "Our cost function corresponds to the negative of the log likelihood. The log likelihood is frequently referred to as $U(\\theta)$ in literature, so our cost function corresponds to $-U(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target parameters\n",
    "parameters = [tf.Variable(0.), tf.Variable(0.)]\n",
    "\n",
    "# cost function\n",
    "def banana_nll(params):\n",
    "    x, y = params\n",
    "    return -1./2. * (x ** 2 / 100. + (y + 0.1 * x ** 2 -10) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these ingredients, we can instantiate any of our samplers within a `tensorflow.Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "sampler = SGHMCSampler(\n",
    "    params=parameters, cost_fun=banana_nll, session=session, dtype=tf.float32\n",
    ")\n",
    "\n",
    "session.run(tf.global_variables_initializer())  # initialize variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data minibatches\n",
    "\n",
    "A major motivation to use Stochastic Gradient MCMC methods is that they leverage MCMC methods\n",
    "to large datasets by *subsampling* them. \n",
    "\n",
    "To this end, our samplers take an iterable *batch_generator* as input and use it to repeatedly subsample the dataset.\n",
    "\n",
    "We provide two simple default ways to generate batches, which can be found in module \n",
    "[pysgmcmc.data_batches](http://pysgmcmc.readthedocs.io/en/latest/api/data_batches.html). \n",
    "You can easily add your own custom batch generation facilities, e.g. by writing a (infinite) generator function that *yields* a dictionary mapping two placeholders for the data to batches of data (usually *np.array*s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "from pysgmcmc.data_batches import generate_batches\n",
    "\n",
    "session = tf.Session()\n",
    "params = [tf.Variable(0., dtype=tf.float64)]\n",
    "\n",
    "def sinc(x):\n",
    "    import numpy as np\n",
    "    return np.sinc(x * 10 - 5).sum(axis=1)\n",
    "\n",
    "# XXX: Use cost function from BNN Negloglikelihood here?\n",
    "# Then, we can even show a batch and run a single iteration \n",
    "dummy_costs = lambda params: tf.reduce_sum(params)  # dummy cost function; ignore this it is not used\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y = sinc(X)\n",
    "\n",
    "x_placeholder, y_placeholder = tf.placeholder(dtype=tf.float64), tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "## Batch Generator (uniform random subsampling) ##\n",
    "batch_generator = generate_batches(X, y, x_placeholder, y_placeholder, batch_size=20)\n",
    "\n",
    "batched_sampler = SGHMCSampler(\n",
    "    params=params, cost_fun=dummy_costs, session=session,\n",
    "    batch_generator=batch_generator  # Pass the iterable into our sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All calls to \n",
    "```python \n",
    "next(batched_sampler)\n",
    "``` \n",
    "will use batches obtained by calling `next(batch_generator)`\n",
    "when computing the costs for the current iteration.\n",
    "\n",
    "Note: the cost function (`cost_fun`) passed to the sampler must use the placeholders passed to `generate_batches`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available samplers\n",
    "\n",
    "To get an overview of which samplers are available for use, examine our [documentation](http://pysgmcmc.readthedocs.io/en/latest/) or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysgmcmc.samplers in pysgmcmc:\n",
      "\n",
      "NAME\n",
      "    pysgmcmc.samplers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    base_classes\n",
      "    relativistic_sghmc\n",
      "    sghmc\n",
      "    sgld\n",
      "    sgnuts\n",
      "    svgd\n",
      "\n",
      "CLASSES\n",
      "    pysgmcmc.samplers.base_classes.BurnInMCMCSampler(pysgmcmc.samplers.base_classes.MCMCSampler)\n",
      "        pysgmcmc.samplers.sghmc.SGHMCSampler\n",
      "        pysgmcmc.samplers.sgld.SGLDSampler\n",
      "    pysgmcmc.samplers.base_classes.MCMCSampler(builtins.object)\n",
      "        pysgmcmc.samplers.relativistic_sghmc.RelativisticSGHMCSampler\n",
      "        pysgmcmc.samplers.svgd.SVGDSampler\n",
      "    \n",
      "    class RelativisticSGHMCSampler(pysgmcmc.samplers.base_classes.MCMCSampler)\n",
      "     |  Relativistic Stochastic Gradient Hamiltonian Monte-Carlo Sampler.\n",
      "     |  \n",
      "     |  See [1] for more details on Relativistic SGHMC.\n",
      "     |  \n",
      "     |  [1] X. Lu, V. Perrone, L. Hasenclever, Y. W. Teh, S. J. Vollmer\n",
      "     |      In Proceedings of the 20 th International Conference on Artificial Intelligence and Statistics (AISTATS) 2017\n",
      "     |  \n",
      "     |      `Relativistic Monte Carlo <http://proceedings.mlr.press/v54/lu17b/lu17b.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RelativisticSGHMCSampler\n",
      "     |      pysgmcmc.samplers.base_classes.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, stepsize_schedule=<pysgmcmc.stepsize_schedules.ConstantStepsizeSchedule object at 0x7f09872bf0b8>, mass=1.0, speed_of_light=1.0, D=1.0, Bhat=0.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      Cost : tensorflow.Tensor\n",
      "     |          1-d Cost tensor that depends on `params`.\n",
      "     |          Frequently denoted as U(theta) in literature.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      stepsize_schedule : pysgmcmc.stepsize_schedules.StepsizeSchedule\n",
      "     |          Iterator class that produces a stream of stepsize values that\n",
      "     |          we can use in our samplers.\n",
      "     |          See also: `pysgmcmc.stepsize_schedules`\n",
      "     |      \n",
      "     |      mass : float, optional\n",
      "     |          mass constant.\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      speed_of_light : float, optional\n",
      "     |          \"Speed of light\" constant. TODO EXTEND DOKU\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      D : float, optional\n",
      "     |          Diffusion constant.\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      Bhat : float, optional\n",
      "     |          TODO: Documentation\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.MCMCSampler:\n",
      "     |          Base class for `RelativisticSGHMCSampler` that specifies how\n",
      "     |          actual sampling is performed (using iterator protocol,\n",
      "     |          e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  __next__(self, feed_dict=None)\n",
      "     |      Compute and return the next sample and\n",
      "     |          next cost values for this sampler.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Extract the next sample (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in = 1000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x:-dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> sample, cost = next(sampler)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "    \n",
      "    class SGHMCSampler(pysgmcmc.samplers.base_classes.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  \n",
      "     |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  \n",
      "     |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      "     |      In Proceedings of Machine Learning Research 32 (2014).\n",
      "     |  \n",
      "     |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGHMCSampler\n",
      "     |      pysgmcmc.samplers.base_classes.BurnInMCMCSampler\n",
      "     |      pysgmcmc.samplers.base_classes.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, stepsize_schedule=<pysgmcmc.stepsize_schedules.ConstantStepsizeSchedule object at 0x7f09508b53c8>, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      stepsize_schedule : pysgmcmc.stepsize_schedules.StepsizeSchedule\n",
      "     |          Iterator class that produces a stream of stepsize values that\n",
      "     |          we can use in our samplers.\n",
      "     |          See also: `pysgmcmc.stepsize_schedules`\n",
      "     |      \n",
      "     |      burn_in_steps : int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      mdecay : float, optional\n",
      "     |          (Constant) momentum decay per time-step.\n",
      "     |          Defaults to `0.05`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |          Defaults to `1.0` which corresponds to no scaling.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_dict=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SGLDSampler(pysgmcmc.samplers.base_classes.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Langevin Dynamics Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Langevin Dynamics.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  [2] M.Welling, Y. W. Teh\n",
      "     |      In International Conference on Machine Learning (ICML) 28 (2011).\n",
      "     |  \n",
      "     |      `Bayesian Learning via Stochastic Gradient Langevin Dynamics. <https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGLDSampler\n",
      "     |      pysgmcmc.samplers.base_classes.BurnInMCMCSampler\n",
      "     |      pysgmcmc.samplers.base_classes.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, stepsize_schedule=<pysgmcmc.stepsize_schedules.ConstantStepsizeSchedule object at 0x7f0950845518>, burn_in_steps=3000, A=1.0, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      stepsize_schedule : pysgmcmc.stepsize_schedules.StepsizeSchedule\n",
      "     |          Iterator class that produces a stream of stepsize values that\n",
      "     |          we can use in our samplers.\n",
      "     |          See also: `pysgmcmc.stepsize_schedules`\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      A : float, optional\n",
      "     |          TODO Doku\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      tensorflow_mcmc.sampling.mcmc_base_classes.BurnInMCMCSampler:\n",
      "     |          Base class for `SGLDSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_dict=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SVGDSampler(pysgmcmc.samplers.base_classes.MCMCSampler)\n",
      "     |  Stein Variational Gradient Descent Sampler.\n",
      "     |  \n",
      "     |  See [1] for more details on stein variational gradient descent.\n",
      "     |  \n",
      "     |  \n",
      "     |  [1] Q. Liu, D. Wang\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm. <https://arxiv.org/pdf/1608.04471>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVGDSampler\n",
      "     |      pysgmcmc.samplers.base_classes.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, particles, cost_fun, batch_generator=None, stepsize_schedule=<pysgmcmc.stepsize_schedules.ConstantStepsizeSchedule object at 0x7f09508457f0>, alpha=0.9, fudge_factor=1e-06, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      particles : List[tensorflow.Variable]\n",
      "     |          List of particles each representing a (different) guess of the\n",
      "     |          target parameters of this sampler.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` of *one* particle as input and\n",
      "     |          returns a 1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      stepsize_schedule : pysgmcmc.stepsize_schedules.StepsizeSchedule\n",
      "     |          Iterator class that produces a stream of stepsize values that\n",
      "     |          we can use in our samplers.\n",
      "     |          See also: `pysgmcmc.stepsize_schedules`\n",
      "     |      \n",
      "     |      alpha : float, optional\n",
      "     |          TODO DOKU\n",
      "     |          Defaults to `0.9`.\n",
      "     |      \n",
      "     |      fudge_factor : float, optional\n",
      "     |          TODO DOKU\n",
      "     |          Defaults to `1e-6`.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.MCMCSampler:\n",
      "     |          Base class for `SteinVariationalGradientDescentSampler` that\n",
      "     |          specifies how actual sampling is performed (using iterator protocol,\n",
      "     |          e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  svgd_kernel(self, particles)\n",
      "     |      Calculate a kernel matrix with corresponding derivatives\n",
      "     |          for the given `particles`.\n",
      "     |          TODO: DOKU ON KERNEL TRICK\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      particles : TODO\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      ----------\n",
      "     |      kernel_matrix : tf.Tensor\n",
      "     |          TODO\n",
      "     |      \n",
      "     |      kernel_gradients : tf.Tensor\n",
      "     |          TODO\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  __next__(self, feed_dict=None)\n",
      "     |      Compute and return the next sample and\n",
      "     |          next cost values for this sampler.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Extract the next sample (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in = 1000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x:-dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> sample, cost = next(sampler)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "\n",
      "DATA\n",
      "    __all__ = ['SGHMCSampler', 'RelativisticSGHMCSampler', 'SGLDSampler', ...\n",
      "\n",
      "FILE\n",
      "    /mhome/freidanm/repos/pysgmcmc/pysgmcmc/samplers/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampler hyperparameters\n",
    "\n",
    "To get a clearer picture of all possible design choices when instantiating any of \n",
    "our samplers, consider our docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGHMCSampler in module pysgmcmc.samplers.sghmc:\n",
      "\n",
      "class SGHMCSampler(pysgmcmc.samplers.base_classes.BurnInMCMCSampler)\n",
      " |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      " |  procedure to adapt its own hyperparameters during the initial stages\n",
      " |  of sampling.\n",
      " |  \n",
      " |  See [1] for more details on this burn-in procedure.\n",
      " |  \n",
      " |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      " |  \n",
      " |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      " |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      " |  \n",
      " |  \n",
      " |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |  \n",
      " |  \n",
      " |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      " |      In Proceedings of Machine Learning Research 32 (2014).\n",
      " |  \n",
      " |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGHMCSampler\n",
      " |      pysgmcmc.samplers.base_classes.BurnInMCMCSampler\n",
      " |      pysgmcmc.samplers.base_classes.MCMCSampler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, cost_fun, batch_generator=None, stepsize_schedule=<pysgmcmc.stepsize_schedules.ConstantStepsizeSchedule object at 0x7f09508b53c8>, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      " |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      " |          for later queries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : list of tensorflow.Variable objects\n",
      " |          Target parameters for which we want to sample new values.\n",
      " |      \n",
      " |      cost_fun : callable\n",
      " |          Function that takes `params` as input and returns a\n",
      " |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      " |          Frequently denoted with `U` in literature.\n",
      " |      \n",
      " |      batch_generator : iterable, optional\n",
      " |          Iterable which returns dictionaries to feed into\n",
      " |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      " |          Defaults to `None` which indicates that no batches shall be fed.\n",
      " |      \n",
      " |      stepsize_schedule : pysgmcmc.stepsize_schedules.StepsizeSchedule\n",
      " |          Iterator class that produces a stream of stepsize values that\n",
      " |          we can use in our samplers.\n",
      " |          See also: `pysgmcmc.stepsize_schedules`\n",
      " |      \n",
      " |      burn_in_steps : int, optional\n",
      " |          Number of burn-in steps to perform. In each burn-in step, this\n",
      " |          sampler will adapt its own internal parameters to decrease its error.\n",
      " |          Defaults to `3000`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      mdecay : float, optional\n",
      " |          (Constant) momentum decay per time-step.\n",
      " |          Defaults to `0.05`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      scale_grad : float, optional\n",
      " |          Value that is used to scale the magnitude of the noise used\n",
      " |          during sampling. In a typical batches-of-data setting this usually\n",
      " |          corresponds to the number of examples in the entire dataset.\n",
      " |          Defaults to `1.0` which corresponds to no scaling.\n",
      " |      \n",
      " |      session : tensorflow.Session, optional\n",
      " |          Session object which knows about the external part of the graph\n",
      " |          (which defines `Cost`, and possibly batches).\n",
      " |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      " |      \n",
      " |      dtype : tensorflow.DType, optional\n",
      " |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      " |          Defaults to `tensorflow.float64`.\n",
      " |      \n",
      " |      seed : int, optional\n",
      " |          Random seed to use.\n",
      " |          Defaults to `None`.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      " |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __next__(self, feed_dict=None)\n",
      " |      Perform a sampler step:\n",
      " |          Compute and return the next sample and next cost values\n",
      " |          for this sampler.\n",
      " |      \n",
      " |          While `self.is_burning_in` returns `True`\n",
      " |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      " |          steps) this will also adapt the samplers mass matrix in a\n",
      " |          sampler-specific way to improve performance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sample: list of numpy.ndarray objects\n",
      " |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      " |      \n",
      " |      cost: numpy.ndarray (1,)\n",
      " |          Current cost value of the last evaluated target parameter values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      " |  \n",
      " |  is_burning_in\n",
      " |      Check if this sampler is still in burn-in phase.\n",
      " |          Used during graph construction to insert conditionals into the\n",
      " |          graph that will make the sampler skip all burn-in operations\n",
      " |          after the burn-in phase is over.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_burning_in: boolean\n",
      " |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pysgmcmc.samplers.base_classes.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows using samplers as iterators.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Extract the first three thousand samples (with costs) from a sampler:\n",
      " |      \n",
      " |      >>> import tensorflow as tf\n",
      " |      >>> import numpy as np\n",
      " |      >>> from itertools import islice\n",
      " |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      " |      >>> session = tf.Session()\n",
      " |      >>> x = tf.Variable(1.0)\n",
      " |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      " |      >>> n_burn_in, n_samples = 1000, 2000\n",
      " |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      " |      >>> session.run(tf.global_variables_initializer())\n",
      " |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      " |      >>> samples = list(islice(sampler, n_samples))\n",
      " |      >>> len(burn_in_samples), len(samples)\n",
      " |      (1000, 2000)\n",
      " |      >>> session.close()\n",
      " |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.samplers.base_classes.MCMCSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers.SGHMCSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting samples\n",
    "\n",
    "Extracting the next sample (with corresponding costs) from any of our samplers always simply amounts to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.0037382236, 0.0019394364], -50.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, cost = next(sampler)\n",
    "\n",
    "sample, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This interface allows us to extract samples in different contexts:\n",
    "\n",
    "1. extract a chain of n subsequent samples\n",
    "2. sample until an external event occurs / an external condition becomes `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. extract a chain of n subsequent samples\n",
    "samples, n = [], 1000\n",
    "\n",
    "\n",
    "for _ in range(n):\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "\n",
    "# shorthand for 1., using itertools.islice\n",
    "import itertools\n",
    "samples = [sample for sample, _ in itertools.islice(sampler, n)]\n",
    "    \n",
    "# 2. sample until an external event occurs\n",
    "\n",
    "# dummy event\n",
    "def external_event():\n",
    "    return np.random.randint(0, 10) > 5\n",
    "\n",
    "samples = []\n",
    "while not external_event():\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "    \n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also allows us to use any of our samplers in (infinite) for-loops. \n",
    "\n",
    "But *be warned*: such a for-loop will **not terminate** unless you explicitly break out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples, i = [], 0\n",
    "for sample, cost in sampler:\n",
    "    if i > 10:\n",
    "        break  # we need to explicitly *break* out of the loop\n",
    "    i += 1\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing chains/traces of samples\n",
    "\n",
    "To analyze the results of a sampler run, we transform the results obtained by our samplers into `pymc3.MultiTrace` objects. Then we can use the (well-established) `pymc3` machinery to compute diagnostics for our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "\n",
    "# XXX: Compute PYSGMCMCTrace (and possibly pymc3.MultiTrace from those) and \n",
    "# use those to compute e.g. ess and maybe produce some plots too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we also provide a shortcut function that directly computes a multitrace for one of our samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pymc3_multitrace in module pysgmcmc.diagnostics.sample_chains:\n",
      "\n",
      "pymc3_multitrace(get_sampler, n_chains=2, samples_per_chain=100, parameter_names=None)\n",
      "    Extract chains from `sampler` and return them as `pymc3.MultiTrace` object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    get_sampler : callable\n",
      "        A callable that takes a `tensorflow.Session` object as input\n",
      "        and returns a (possibly already burnt-in) instance of a\n",
      "        `pysgmcmc.sampling.MCMCSampler` subclass.\n",
      "    \n",
      "    parameter_names : List[String] or NoneType, optional\n",
      "        List of names for each target parameter of the sampler.\n",
      "        If set to `None`, simply enumerate the parameters and use those numbers\n",
      "        as names.\n",
      "        Defaults to `None`.\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    multitrace : pymc3.backends.base.MultiTrace\n",
      "        TODO: DOKU\n",
      "    \n",
      "    Examples\n",
      "    ----------\n",
      "    TODO ADD EXAMPLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.diagnostics.sample_chains.pymc3_multitrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PYSGMCMC - trained BNN\n",
    "\n",
    "We provide an implementation of a Bayesian Neural Network that is trained using our samplers. \n",
    "\n",
    "The (tensorflow-) architecture of this BNN can be customized by the user and any of our sampling methods can be used to sample networks during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noYai+IcQQg1F8Q8hhBqK4h9CCDX0L+Qd3KENildeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0918164710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pysgmcmc.diagnostics.objective_functions import sinc\n",
    "from pysgmcmc.models.bayesian_neural_network import BayesianNeuralNetwork\n",
    "from pysgmcmc.sampling import Sampler\n",
    "from pysgmcmc.stepsize_schedules import ConstantStepsizeSchedule\n",
    "\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X_train = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y_train = sinc(X_train)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)[:, None]\n",
    "y_test = sinc(X_test)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "session = tf.InteractiveSession(graph=g)\n",
    "with g.as_default():\n",
    "    model = BayesianNeuralNetwork(\n",
    "        session=session, batch_size=20, sampling_method=Sampler.SGHMC,\n",
    "        burn_in_steps=3000, n_iters=50000, \n",
    "        normalize_input=True, normalize_output=True,\n",
    "        stepsize_schedule=ConstantStepsizeSchedule(np.sqrt(1e-4)),\n",
    "        dtype=tf.float32,\n",
    "        # sampler arguments for SGHMC\n",
    "        mdecay=0.05,         \n",
    "    )\n",
    "    model.train(X_train, y_train)\n",
    "    prediction_mean, prediction_variance = model.predict(X_test)\n",
    "\n",
    "prediction_std = np.sqrt(prediction_variance)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(X_test[:, 0], y_test, label=\"true\", color=\"black\")\n",
    "plt.plot(X_train[:, 0], y_train, \"ro\")\n",
    "\n",
    "plt.plot(X_test[:, 0], prediction_mean, label=\"SGHMC\", color=\"blue\")\n",
    "plt.fill_between(X_test[:, 0], prediction_mean + prediction_std, prediction_mean - prediction_std, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
