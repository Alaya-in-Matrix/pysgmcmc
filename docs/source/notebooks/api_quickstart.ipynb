{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(\"..\", \"..\", \"..\")))\n",
    "import pysgmcmc as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating a Sampler\n",
    "\n",
    "To instantiate a sampler, we need two ingredients:\n",
    "\n",
    "1. Target parameters of the sampler: a list of `tensorflow.Variable` objects \n",
    "2. A cost function: callable that maps these target parameters to a 1-d `tensorflow.Tensor` representing their corresponding costs\n",
    "\n",
    "Note: In MCMC literature, the target parameters are often denoted as $\\theta$ and the cost function is frequently referred to as $U(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target parameters\n",
    "parameters = [tf.Variable(0.), tf.Variable(0.)]\n",
    "\n",
    "# cost function\n",
    "def banana_nll(params):\n",
    "    x, y = params\n",
    "    return -1./2. * (x ** 2 / 100. + (y + 0.1 * x ** 2 -10) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these ingredients, we can instantiate any of our samplers within a `tensorflow.Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "sampler = SGHMCSampler(\n",
    "    params=parameters, cost_fun=banana_nll, session=session, dtype=tf.float32\n",
    ")\n",
    "\n",
    "session.run(tf.global_variables_initializer())  # initialize variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data minibatches\n",
    "\n",
    "A major motivation to use Stochastic Gradient MCMC methods is that they leverage MCMC methods\n",
    "to large datasets by *subsampling* them. \n",
    "\n",
    "To this end, our samplers take an iterable *batch_generator* as input and use it to repeatedly subsample the dataset.\n",
    "\n",
    "We provide two simple default ways to generate batches, which can be found in module \n",
    "[pysgmcmc.data_batches](http://pysgmcmc.readthedocs.io/en/latest/api/data_batches.html). \n",
    "You can easily add your own custom batch generation facilities, e.g. by writing a (infinite) generator function that *yields* a dictionary mapping two placeholders for the data to batches of data (usually *np.array*s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "from pysgmcmc.data_batches import generate_batches\n",
    "\n",
    "session = tf.Session()\n",
    "params = [tf.Variable(0., dtype=tf.float64)]\n",
    "\n",
    "def sinc(x):\n",
    "    import numpy as np\n",
    "    return np.sinc(x * 10 - 5).sum(axis=1)\n",
    "\n",
    "# XXX: Use cost function from BNN Negloglikelihood here?\n",
    "# Then, we can even show a batch and run a single iteration \n",
    "dummy_costs = lambda params: tf.reduce_sum(params)  # dummy cost function; ignore this it is not used\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y = sinc(X)\n",
    "\n",
    "x_placeholder, y_placeholder = tf.placeholder(dtype=tf.float64), tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "## Batch Generator (uniform random subsampling) ##\n",
    "batch_generator = generate_batches(X, y, x_placeholder, y_placeholder, batch_size=20)\n",
    "\n",
    "batched_sampler = SGHMCSampler(\n",
    "    params=params, cost_fun=dummy_costs, session=session,\n",
    "    batch_generator=batch_generator  # Pass the iterable into our sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All calls to \n",
    "```python \n",
    "next(batched_sampler)\n",
    "``` \n",
    "will use batches obtained by calling `next(batch_generator)`\n",
    "when computing the costs for the current iteration.\n",
    "\n",
    "Note: the cost function (`cost_fun`) passed to the sampler must use the placeholders passed to `generate_batches`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available samplers\n",
    "\n",
    "To get an overview of which samplers are available for use, examine our [documentation](http://pysgmcmc.readthedocs.io/en/latest/) or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysgmcmc.samplers in pysgmcmc:\n",
      "\n",
      "NAME\n",
      "    pysgmcmc.samplers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    relativistic_hmc\n",
      "    relativistic_sghmc\n",
      "    sghmc\n",
      "    sgld\n",
      "\n",
      "CLASSES\n",
      "    pysgmcmc.sampling.BurnInMCMCSampler(pysgmcmc.sampling.MCMCSampler)\n",
      "        pysgmcmc.samplers.sghmc.SGHMCSampler\n",
      "        pysgmcmc.samplers.sgld.SGLDSampler\n",
      "    \n",
      "    class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  \n",
      "     |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  \n",
      "     |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      "     |      In Proceedings of Machine Learning Research 32 (2014).\n",
      "     |  \n",
      "     |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGHMCSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      mdecay : float, optional\n",
      "     |          (Constant) momentum decay per time-step.\n",
      "     |          Defaults to `0.05`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |          Defaults to `1.0` which corresponds to no scaling.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_vals=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SGLDSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Langevin Dynamics Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Langevin Dynamics.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |  \n",
      "     |  [2] M.Welling, Y. W. Teh\n",
      "     |      In International Conference on Machine Learning (ICML) 28 (2011).\n",
      "     |  \n",
      "     |      `Bayesian Learning via Stochastic Gradient Langevin Dynamics. <https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGLDSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, A=1.0, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          Defaults to `3000`.\n",
      "     |      \n",
      "     |          For reference see:\n",
      "     |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      "     |      \n",
      "     |      A : float, optional\n",
      "     |          TODO Doku\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      tensorflow_mcmc.sampling.mcmc_base_classes.BurnInMCMCSampler:\n",
      "     |          Base class for `SGLDSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self, feed_vals=None)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['SGHMCSampler', 'SGLDSampler']\n",
      "\n",
      "FILE\n",
      "    /mhome/freidanm/repos/pysgmcmc/pysgmcmc/samplers/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampler hyperparameters\n",
    "\n",
    "To get a clearer picture of all possible design choices when instantiating any of \n",
    "our samplers, consider our docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGHMCSampler in module pysgmcmc.samplers.sghmc:\n",
      "\n",
      "class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      " |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      " |  procedure to adapt its own hyperparameters during the initial stages\n",
      " |  of sampling.\n",
      " |  \n",
      " |  See [1] for more details on this burn-in procedure.\n",
      " |  \n",
      " |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      " |  \n",
      " |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      " |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      " |  \n",
      " |      `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |  \n",
      " |  \n",
      " |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      " |      In Proceedings of Machine Learning Research 32 (2014).\n",
      " |  \n",
      " |      `Stochastic Gradient Hamiltonian Monte Carlo <https://arxiv.org/pdf/1402.4102.pdf>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGHMCSampler\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      " |      pysgmcmc.sampling.MCMCSampler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, cost_fun, batch_generator=None, epsilon=0.01, burn_in_steps=3000, mdecay=0.05, scale_grad=1.0, session=None, dtype=tf.float64, seed=None)\n",
      " |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      " |          for later queries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : list of tensorflow.Variable objects\n",
      " |          Target parameters for which we want to sample new values.\n",
      " |      \n",
      " |      cost_fun : callable\n",
      " |          Function that takes `params` as input and returns a\n",
      " |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      " |          Frequently denoted with `U` in literature.\n",
      " |      \n",
      " |      batch_generator : iterable, optional\n",
      " |          Iterable which returns dictionaries to feed into\n",
      " |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      " |          Defaults to `None` which indicates that no batches shall be fed.\n",
      " |      \n",
      " |      epsilon : float, optional\n",
      " |          Value that is used as learning rate parameter for the sampler,\n",
      " |          also denoted as discretization parameter in literature.\n",
      " |          Defaults to `0.01`.\n",
      " |      \n",
      " |      burn_in_steps: int, optional\n",
      " |          Number of burn-in steps to perform. In each burn-in step, this\n",
      " |          sampler will adapt its own internal parameters to decrease its error.\n",
      " |          Defaults to `3000`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      mdecay : float, optional\n",
      " |          (Constant) momentum decay per time-step.\n",
      " |          Defaults to `0.05`.\n",
      " |      \n",
      " |          For reference see:\n",
      " |          `Bayesian Optimization with Robust Bayesian Neural Networks. <http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf>`_\n",
      " |      \n",
      " |      scale_grad : float, optional\n",
      " |          Value that is used to scale the magnitude of the noise used\n",
      " |          during sampling. In a typical batches-of-data setting this usually\n",
      " |          corresponds to the number of examples in the entire dataset.\n",
      " |          Defaults to `1.0` which corresponds to no scaling.\n",
      " |      \n",
      " |      session : tensorflow.Session, optional\n",
      " |          Session object which knows about the external part of the graph\n",
      " |          (which defines `Cost`, and possibly batches).\n",
      " |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      " |      \n",
      " |      dtype : tensorflow.DType, optional\n",
      " |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      " |          Defaults to `tensorflow.float64`.\n",
      " |      \n",
      " |      seed : int, optional\n",
      " |          Random seed to use.\n",
      " |          Defaults to `None`.\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      " |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __next__(self, feed_vals=None)\n",
      " |      Perform a sampler step:\n",
      " |          Compute and return the next sample and next cost values\n",
      " |          for this sampler.\n",
      " |      \n",
      " |          While `self.is_burning_in` returns `True`\n",
      " |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      " |          steps) this will also adapt the samplers mass matrix in a\n",
      " |          sampler-specific way to improve performance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sample: list of numpy.ndarray objects\n",
      " |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      " |      \n",
      " |      cost: numpy.ndarray (1,)\n",
      " |          Current cost value of the last evaluated target parameter values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  is_burning_in\n",
      " |      Check if this sampler is still in burn-in phase.\n",
      " |          Used during graph construction to insert conditionals into the\n",
      " |          graph that will make the sampler skip all burn-in operations\n",
      " |          after the burn-in phase is over.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_burning_in: boolean\n",
      " |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows using samplers as iterators.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Extract the first three thousand samples (with costs) from a sampler:\n",
      " |      \n",
      " |      >>> import tensorflow as tf\n",
      " |      >>> import numpy as np\n",
      " |      >>> from itertools import islice\n",
      " |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      " |      >>> session = tf.Session()\n",
      " |      >>> x = tf.Variable(1.0)\n",
      " |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      " |      >>> n_burn_in, n_samples = 1000, 2000\n",
      " |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      " |      >>> session.run(tf.global_variables_initializer())\n",
      " |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      " |      >>> samples = list(islice(sampler, n_samples))\n",
      " |      >>> len(burn_in_samples), len(samples)\n",
      " |      (1000, 2000)\n",
      " |      >>> session.close()\n",
      " |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers.SGHMCSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting samples\n",
    "\n",
    "Extracting the next sample (with corresponding costs) from any of our samplers always simply amounts to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0037098911, -0.0052928207], -50.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, cost = next(sampler)\n",
    "\n",
    "sample, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This interface allows us to extract samples in different contexts:\n",
    "\n",
    "1. extract a chain of n subsequent samples\n",
    "2. sample until an external event occurs / an external condition becomes `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0083967, -3.6901648], [-1.0053477, -3.6912839]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. extract a chain of n subsequent samples\n",
    "samples, n = [], 1000\n",
    "\n",
    "\n",
    "for _ in range(n):\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "\n",
    "# shorthand for 1., using itertools.islice\n",
    "import itertools\n",
    "samples = [sample for sample, _ in itertools.islice(sampler, n)]\n",
    "    \n",
    "# 2. sample until an external event occurs\n",
    "\n",
    "# dummy event\n",
    "def external_event():\n",
    "    return np.random.randint(0, 10) > 5\n",
    "\n",
    "samples = []\n",
    "while not external_event():\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "    \n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also allows us to use any of our samplers in (infinite) for-loops. \n",
    "\n",
    "But *be warned*: such a for-loop will **not terminate** unless you explicitly break out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples, i = [], 0\n",
    "for sample, cost in sampler:\n",
    "    if i > 10:\n",
    "        break  # we need to explicitly *break* out of the loop\n",
    "    i += 1\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing chains/traces of samples\n",
    "\n",
    "To analyze the results of a sampler run, we transform the results obtained by our samplers into `pymc3.MultiTrace` objects. Then we can use the (well-established) `pymc3` machinery to compute diagnostics for our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "\n",
    "# XXX: Compute PYSGMCMCTrace (and possibly pymc3.MultiTrace from those) and \n",
    "# use those to compute e.g. ess and maybe produce some plots too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we also provide a shortcut function that directly computes a multitrace for one of our samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pymc3_multitrace in module pysgmcmc.diagnostics.sample_chains:\n",
      "\n",
      "pymc3_multitrace(get_sampler, n_chains=2, samples_per_chain=100, parameter_names=None)\n",
      "    Extract chains from `sampler` and return them as `pymc3.MultiTrace` object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    get_sampler : callable\n",
      "        A callable that takes a `tensorflow.Session` object as input\n",
      "        and returns a (possibly already burnt-in) instance of a\n",
      "        `pysgmcmc.sampling.MCMCSampler` subclass.\n",
      "    \n",
      "    parameter_names : List[String] or NoneType, optional\n",
      "        List of names for each target parameter of the sampler.\n",
      "        If set to `None`, simply enumerate the parameters and use those numbers\n",
      "        as names.\n",
      "        Defaults to `None`.\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    multitrace : pymc3.backends.base.MultiTrace\n",
      "        TODO: DOKU\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    ----------\n",
      "    TODO ADD EXAMPLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.diagnostics.sample_chains.pymc3_multitrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PYSGMCMC - trained BNN\n",
    "\n",
    "We provide an implementation of a Bayesian Neural Network that is trained using our samplers. \n",
    "\n",
    "The (tensorflow-) architecture of this BNN can be customized by the user and any of our sampling methods can be used to sample networks during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhxBCB3oKBDOWuMJtfGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d1be1eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pysgmcmc.diagnostics.objective_functions import sinc\n",
    "from pysgmcmc.models.bayesian_neural_network import BayesianNeuralNetwork\n",
    "from pysgmcmc.sampling import Sampler\n",
    "\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X_train = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y_train = sinc(X_train)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)[:, None]\n",
    "y_test = sinc(X_test)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "session = tf.InteractiveSession(graph=g)\n",
    "with g.as_default():\n",
    "    model = BayesianNeuralNetwork(\n",
    "        session=session, batch_size=20, sampling_method=Sampler.SGHMC,\n",
    "        burn_in_steps=3000, n_iters=50000, \n",
    "        normalize_input=True, normalize_output=True,\n",
    "        learning_rate=np.sqrt(1e-4),\n",
    "        # sampler arguments for SGHMC\n",
    "        mdecay=0.05,         \n",
    "    )\n",
    "    model.train(X_train, y_train)\n",
    "    prediction_mean, prediction_variance = model.predict(X_test)\n",
    "\n",
    "prediction_std = np.sqrt(prediction_variance)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(X_test[:, 0], y_test, label=\"true\", color=\"black\")\n",
    "plt.plot(X_train[:, 0], y_train, \"ro\")\n",
    "\n",
    "plt.plot(X_test[:, 0], prediction_mean, label=\"SGHMC\", color=\"blue\")\n",
    "plt.fill_between(X_test[:, 0], prediction_mean + prediction_std, prediction_mean - prediction_std, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
