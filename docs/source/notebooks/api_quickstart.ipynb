{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(\"..\", \"..\", \"..\")))\n",
    "import pysgmcmc as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating a Sampler\n",
    "\n",
    "To instantiate a sampler, we need two ingredients:\n",
    "\n",
    "1. Target parameters of the sampler: a list of `tensorflow.Variable` objects \n",
    "2. A cost function: callable that maps these target parameters to a 1-d `tensorflow.Tensor` representing their corresponding costs\n",
    "\n",
    "Note: In MCMC literature, the target parameters are often denoted as $\\theta$ and the cost function is frequently referred to as $U(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target parameters\n",
    "parameters = [tf.Variable(0.), tf.Variable(0.)]\n",
    "\n",
    "# cost function\n",
    "def banana_nll(params):\n",
    "    x, y = params\n",
    "    return -1./2. * (x ** 2 / 100. + (y + 0.1 * x ** 2 -10) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these ingredients, we can instantiate any of our samplers within a `tensorflow.Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "sampler = SGHMCSampler(\n",
    "    params=parameters, cost_fun=banana_nll, session=session, dtype=tf.float32\n",
    ")\n",
    "\n",
    "session.run(tf.global_variables_initializer())  # initialize variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data minibatches\n",
    "\n",
    "A major motivation to use Stochastic Gradient MCMC methods is that they leverage MCMC methods\n",
    "to large datasets by *subsampling* them. \n",
    "\n",
    "To this end, our samplers take an iterable *batch_generator* as input and use it to repeatedly subsample the dataset.\n",
    "\n",
    "We provide two simple default ways to generate batches, which can be found in module \n",
    "[pysgmcmc.data_batches](http://pysgmcmc.readthedocs.io/en/latest/api/data_batches.html). \n",
    "You can easily add your own custom batch generation facilities, e.g. by writing a (infinite) generator function that *yields* a dictionary mapping two placeholders for the data to batches of data (usually *np.array*s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
    "from pysgmcmc.data_batches import generate_batches\n",
    "\n",
    "session = tf.Session()\n",
    "params = [tf.Variable(0., dtype=tf.float64)]\n",
    "\n",
    "def sinc(x):\n",
    "    import numpy as np\n",
    "    return np.sinc(x * 10 - 5).sum(axis=1)\n",
    "\n",
    "# XXX: Use cost function from BNN Negloglikelihood here?\n",
    "# Then, we can even show a batch and run a single iteration \n",
    "dummy_costs = lambda params: tf.reduce_sum(params)  # dummy cost function; ignore this it is not used\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y = sinc(X)\n",
    "\n",
    "x_placeholder, y_placeholder = tf.placeholder(dtype=tf.float64), tf.placeholder(dtype=tf.float64)\n",
    "\n",
    "## Batch Generator (uniform random subsampling) ##\n",
    "batch_generator = generate_batches(X, y, x_placeholder, y_placeholder, batch_size=20)\n",
    "\n",
    "batched_sampler = SGHMCSampler(\n",
    "    params=params, cost_fun=dummy_costs, session=session,\n",
    "    batch_generator=batch_generator  # Pass the iterable into our sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All calls to \n",
    "```python \n",
    "next(batched_sampler)\n",
    "``` \n",
    "will use batches obtained by calling `next(batch_generator)`\n",
    "when computing the costs for the current iteration.\n",
    "\n",
    "Note: the cost function (`cost_fun`) passed to the sampler must use the placeholders passed to `generate_batches`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available samplers\n",
    "\n",
    "To get an overview of which samplers are available for use, examine our [documentation](http://pysgmcmc.readthedocs.io/en/latest/) or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pysgmcmc.samplers in pysgmcmc:\n",
      "\n",
      "NAME\n",
      "    pysgmcmc.samplers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    relativistic_hmc\n",
      "    relativistic_sghmc\n",
      "    sghmc\n",
      "    sgld\n",
      "\n",
      "CLASSES\n",
      "    pysgmcmc.sampling.BurnInMCMCSampler(pysgmcmc.sampling.MCMCSampler)\n",
      "        pysgmcmc.samplers.sghmc.SGHMCSampler\n",
      "        pysgmcmc.samplers.sgld.SGLDSampler\n",
      "    \n",
      "    class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      "     |      Stochastic Gradient Hamiltonian Monte Carlo\n",
      "     |      In Proceedings of Machine Learning Research 32 (2014).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGHMCSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, mdecay=0.05)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      batch_generator : iterable, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |          Defaults to `1.0` which corresponds to no scaling.\n",
      "     |      \n",
      "     |      dtype : tensorflow.DType, optional\n",
      "     |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      "     |          Defaults to `tensorflow.float64`.\n",
      "     |      \n",
      "     |      mdecay : float, optional\n",
      "     |          (Constant) momentum decay per time-step.\n",
      "     |          Defaults to `0.05`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Simple, plain example:\n",
      "     |      TODO: Add 2D Gaussian Case here\n",
      "     |      \n",
      "     |      Simple example that uses batches:\n",
      "     |      TODO: Add simplified batch example here\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SGLDSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      "     |  Stochastic Gradient Langevin Dynamics Sampler that uses a burn-in\n",
      "     |  procedure to adapt its own hyperparameters during the initial stages\n",
      "     |  of sampling.\n",
      "     |  \n",
      "     |  See [1] for more details on this burn-in procedure.\n",
      "     |  See [2] for more details on Stochastic Gradient Langevin Dynamics.\n",
      "     |  \n",
      "     |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      "     |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      "     |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      "     |  \n",
      "     |  [2] M.Welling, Y. W. Teh\n",
      "     |      Bayesian Learning via Stochastic Gradient Langevin Dynamics\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SGLDSampler\n",
      "     |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      "     |      pysgmcmc.sampling.MCMCSampler\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, A=1.0)\n",
      "     |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      "     |          for later queries.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : list of tensorflow.Variable objects\n",
      "     |          Target parameters for which we want to sample new values.\n",
      "     |      \n",
      "     |      cost_fun : callable\n",
      "     |          Function that takes `params` as input and returns a\n",
      "     |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      "     |          Frequently denoted with `U` in literature.\n",
      "     |      \n",
      "     |      seed : int, optional\n",
      "     |          Random seed to use.\n",
      "     |          Defaults to `None`.\n",
      "     |      \n",
      "     |      batch_generator : BatchGenerator, optional\n",
      "     |          Iterable which returns dictionaries to feed into\n",
      "     |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      "     |          Defaults to `None` which indicates that no batches shall be fed.\n",
      "     |      \n",
      "     |      epsilon : float, optional\n",
      "     |          Value that is used as learning rate parameter for the sampler,\n",
      "     |          also denoted as discretization parameter in literature.\n",
      "     |          Defaults to `0.01`.\n",
      "     |      \n",
      "     |      session : tensorflow.Session, optional\n",
      "     |          Session object which knows about the external part of the graph\n",
      "     |          (which defines `Cost`, and possibly batches).\n",
      "     |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      "     |      \n",
      "     |      burn_in_steps: int, optional\n",
      "     |          Number of burn-in steps to perform. In each burn-in step, this\n",
      "     |          sampler will adapt its own internal parameters to decrease its error.\n",
      "     |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      "     |      \n",
      "     |      scale_grad : float, optional\n",
      "     |          Value that is used to scale the magnitude of the noise used\n",
      "     |          during sampling. In a typical batches-of-data setting this usually\n",
      "     |          corresponds to the number of examples in the entire dataset.\n",
      "     |      \n",
      "     |      A : float, optional\n",
      "     |          TODO XXX Doku\n",
      "     |          Defaults to `1.0`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Simple, plain example:\n",
      "     |      TODO: Add more samples\n",
      "     |      \n",
      "     |      Simple example that uses batches:\n",
      "     |      TODO: Add simplified batch example here\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ----------\n",
      "     |      tensorflow_mcmc.sampling.mcmc_base_classes.BurnInMCMCSampler:\n",
      "     |          Base class for `SGLDSampler` that specifies how actual sampling\n",
      "     |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      Perform a sampler step:\n",
      "     |          Compute and return the next sample and next cost values\n",
      "     |          for this sampler.\n",
      "     |      \n",
      "     |          While `self.is_burning_in` returns `True`\n",
      "     |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      "     |          steps) this will also adapt the samplers mass matrix in a\n",
      "     |          sampler-specific way to improve performance.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sample: list of numpy.ndarray objects\n",
      "     |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      "     |      \n",
      "     |      cost: numpy.ndarray (1,)\n",
      "     |          Current cost value of the last evaluated target parameter values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  is_burning_in\n",
      "     |      Check if this sampler is still in burn-in phase.\n",
      "     |          Used during graph construction to insert conditionals into the\n",
      "     |          graph that will make the sampler skip all burn-in operations\n",
      "     |          after the burn-in phase is over.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_burning_in: boolean\n",
      "     |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      "     |  \n",
      "     |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      "     |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      "     |      \n",
      "     |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      "     |      directly, and then acts as a mix-in class.  You can also register\n",
      "     |      unrelated concrete classes (even built-in classes) and unrelated\n",
      "     |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      "     |      be considered subclasses of the registering ABC by the built-in\n",
      "     |      issubclass() function, but the registering ABC won't show up in\n",
      "     |      their MRO (Method Resolution Order) nor will method\n",
      "     |      implementations defined by the registering ABC be callable (not\n",
      "     |      even via super()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Allows using samplers as iterators.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      ----------\n",
      "     |      Extract the first three thousand samples (with costs) from a sampler:\n",
      "     |      \n",
      "     |      >>> import tensorflow as tf\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> from itertools import islice\n",
      "     |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      "     |      >>> session = tf.Session()\n",
      "     |      >>> x = tf.Variable(1.0)\n",
      "     |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      "     |      >>> n_burn_in, n_samples = 1000, 2000\n",
      "     |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      "     |      >>> session.run(tf.global_variables_initializer())\n",
      "     |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      "     |      >>> samples = list(islice(sampler, n_samples))\n",
      "     |      >>> len(burn_in_samples), len(samples)\n",
      "     |      (1000, 2000)\n",
      "     |      >>> session.close()\n",
      "     |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['SGHMCSampler', 'SGLDSampler']\n",
      "\n",
      "FILE\n",
      "    /home/moritz/pysgmcmc/pysgmcmc/samplers/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampler hyperparameters\n",
    "\n",
    "To get a clearer picture of all possible design choices when instantiating any of \n",
    "our samplers, consider our docstrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SGHMCSampler in module pysgmcmc.samplers.sghmc:\n",
      "\n",
      "class SGHMCSampler(pysgmcmc.sampling.BurnInMCMCSampler)\n",
      " |  Stochastic Gradient Hamiltonian Monte-Carlo Sampler that uses a burn-in\n",
      " |  procedure to adapt its own hyperparameters during the initial stages\n",
      " |  of sampling.\n",
      " |  \n",
      " |  See [1] for more details on this burn-in procedure.\n",
      " |  See [2] for more details on Stochastic Gradient Hamiltonian Monte-Carlo.\n",
      " |  \n",
      " |  [1] J. T. Springenberg, A. Klein, S. Falkner, F. Hutter\n",
      " |      Bayesian Optimization with Robust Bayesian Neural Networks.\n",
      " |      In Advances in Neural Information Processing Systems 29 (2016).\n",
      " |  \n",
      " |  [2] T. Chen, E. B. Fox, C. Guestrin\n",
      " |      Stochastic Gradient Hamiltonian Monte Carlo\n",
      " |      In Proceedings of Machine Learning Research 32 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SGHMCSampler\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler\n",
      " |      pysgmcmc.sampling.MCMCSampler\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, params, cost_fun, seed=None, batch_generator=None, epsilon=0.01, session=None, burn_in_steps=3000, scale_grad=1.0, dtype=tf.float64, mdecay=0.05)\n",
      " |      Initialize the sampler parameters and set up a tensorflow.Graph\n",
      " |          for later queries.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : list of tensorflow.Variable objects\n",
      " |          Target parameters for which we want to sample new values.\n",
      " |      \n",
      " |      cost_fun : callable\n",
      " |          Function that takes `params` as input and returns a\n",
      " |          1-d `tensorflow.Tensor` that contains the cost-value.\n",
      " |          Frequently denoted with `U` in literature.\n",
      " |      \n",
      " |      seed : int, optional\n",
      " |          Random seed to use.\n",
      " |          Defaults to `None`.\n",
      " |      \n",
      " |      batch_generator : iterable, optional\n",
      " |          Iterable which returns dictionaries to feed into\n",
      " |          tensorflow.Session.run() calls to evaluate the cost function.\n",
      " |          Defaults to `None` which indicates that no batches shall be fed.\n",
      " |      \n",
      " |      epsilon : float, optional\n",
      " |          Value that is used as learning rate parameter for the sampler,\n",
      " |          also denoted as discretization parameter in literature.\n",
      " |          Defaults to `0.01`.\n",
      " |      \n",
      " |      session : tensorflow.Session, optional\n",
      " |          Session object which knows about the external part of the graph\n",
      " |          (which defines `Cost`, and possibly batches).\n",
      " |          Used internally to evaluate (burn-in/sample) the sampler.\n",
      " |      \n",
      " |      burn_in_steps: int, optional\n",
      " |          Number of burn-in steps to perform. In each burn-in step, this\n",
      " |          sampler will adapt its own internal parameters to decrease its error.\n",
      " |          For reference see: TODO ADD PAPER REFERENCE HERE\n",
      " |      \n",
      " |      scale_grad : float, optional\n",
      " |          Value that is used to scale the magnitude of the noise used\n",
      " |          during sampling. In a typical batches-of-data setting this usually\n",
      " |          corresponds to the number of examples in the entire dataset.\n",
      " |          Defaults to `1.0` which corresponds to no scaling.\n",
      " |      \n",
      " |      dtype : tensorflow.DType, optional\n",
      " |          Type of elements of `tensorflow.Tensor` objects used in this sampler.\n",
      " |          Defaults to `tensorflow.float64`.\n",
      " |      \n",
      " |      mdecay : float, optional\n",
      " |          (Constant) momentum decay per time-step.\n",
      " |          Defaults to `0.05`.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Simple, plain example:\n",
      " |      TODO: Add 2D Gaussian Case here\n",
      " |      \n",
      " |      Simple example that uses batches:\n",
      " |      TODO: Add simplified batch example here\n",
      " |      \n",
      " |      See Also\n",
      " |      ----------\n",
      " |      pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |          Base class for `SGHMCSampler` that specifies how actual sampling\n",
      " |          is performed (using iterator protocol, e.g. `next(sampler)`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __next__(self)\n",
      " |      Perform a sampler step:\n",
      " |          Compute and return the next sample and next cost values\n",
      " |          for this sampler.\n",
      " |      \n",
      " |          While `self.is_burning_in` returns `True`\n",
      " |          (while the sampler has not yet performed `self.burn_in_steps`\n",
      " |          steps) this will also adapt the samplers mass matrix in a\n",
      " |          sampler-specific way to improve performance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sample: list of numpy.ndarray objects\n",
      " |          Sampled values are a `numpy.ndarray` for each target parameter.\n",
      " |      \n",
      " |      cost: numpy.ndarray (1,)\n",
      " |          Current cost value of the last evaluated target parameter values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  is_burning_in\n",
      " |      Check if this sampler is still in burn-in phase.\n",
      " |          Used during graph construction to insert conditionals into the\n",
      " |          graph that will make the sampler skip all burn-in operations\n",
      " |          after the burn-in phase is over.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_burning_in: boolean\n",
      " |          `True` if `self.n_iterations <= self.burn_in_steps`, otherwise `False`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pysgmcmc.sampling.BurnInMCMCSampler:\n",
      " |  \n",
      " |  __metaclass__ = <class 'abc.ABCMeta'>\n",
      " |      Metaclass for defining Abstract Base Classes (ABCs).\n",
      " |      \n",
      " |      Use this metaclass to create an ABC.  An ABC can be subclassed\n",
      " |      directly, and then acts as a mix-in class.  You can also register\n",
      " |      unrelated concrete classes (even built-in classes) and unrelated\n",
      " |      ABCs as 'virtual subclasses' -- these and their descendants will\n",
      " |      be considered subclasses of the registering ABC by the built-in\n",
      " |      issubclass() function, but the registering ABC won't show up in\n",
      " |      their MRO (Method Resolution Order) nor will method\n",
      " |      implementations defined by the registering ABC be callable (not\n",
      " |      even via super()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Allows using samplers as iterators.\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      Extract the first three thousand samples (with costs) from a sampler:\n",
      " |      \n",
      " |      >>> import tensorflow as tf\n",
      " |      >>> import numpy as np\n",
      " |      >>> from itertools import islice\n",
      " |      >>> from pysgmcmc.samplers.sghmc import SGHMCSampler\n",
      " |      >>> session = tf.Session()\n",
      " |      >>> x = tf.Variable(1.0)\n",
      " |      >>> dist = tf.contrib.distributions.Normal(loc=0., scale=1.)\n",
      " |      >>> n_burn_in, n_samples = 1000, 2000\n",
      " |      >>> sampler = SGHMCSampler(params=[x], burn_in_steps=n_burn_in, cost_fun=lambda x: -dist.log_prob(x), session=session, dtype=tf.float32)\n",
      " |      >>> session.run(tf.global_variables_initializer())\n",
      " |      >>> burn_in_samples = list(islice(sampler, n_burn_in))  # perform all burn_in steps\n",
      " |      >>> samples = list(islice(sampler, n_samples))\n",
      " |      >>> len(burn_in_samples), len(samples)\n",
      " |      (1000, 2000)\n",
      " |      >>> session.close()\n",
      " |      >>> tf.reset_default_graph()  # to avoid polluting test environment\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pysgmcmc.sampling.MCMCSampler:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.samplers.SGHMCSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting samples\n",
    "\n",
    "Extracting the next sample (with corresponding costs) from any of our samplers always simply amounts to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.00053981662, -0.0037057472], -50.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample, cost = next(sampler)\n",
    "\n",
    "sample, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This interface allows us to extract samples in different contexts:\n",
    "\n",
    "1. extract a chain of n subsequent samples\n",
    "2. sample until an external event occurs / an external condition becomes `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. extract a chain of n subsequent samples\n",
    "samples, n = [], 1000\n",
    "\n",
    "\n",
    "for _ in range(n):\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "\n",
    "# shorthand for 1., using itertools.islice\n",
    "import itertools\n",
    "samples = [sample for sample, _ in itertools.islice(sampler, n)]\n",
    "    \n",
    "# 2. sample until an external event occurs\n",
    "\n",
    "# dummy event\n",
    "def external_event():\n",
    "    return np.random.randint(0, 10) > 5\n",
    "\n",
    "samples = []\n",
    "while not external_event():\n",
    "    sample, _ = next(sampler)\n",
    "    samples.append(sample)\n",
    "    \n",
    "    \n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also allows us to use any of our samplers in (infinite) for-loops. \n",
    "\n",
    "But *be warned*: such a for-loop will **not terminate** unless you explicitly break out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples, i = [], 0\n",
    "for sample, cost in sampler:\n",
    "    if i > 10:\n",
    "        break  # we need to explicitly *break* out of the loop\n",
    "    i += 1\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing chains/traces of samples\n",
    "\n",
    "To analyze the results of a sampler run, we transform the results obtained by our samplers into `pymc3.MultiTrace` objects. Then we can use the (well-established) `pymc3` machinery to compute diagnostics for our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysgmcmc.diagnostics.sample_chains import PYSGMCMCTrace\n",
    "\n",
    "# XXX: Compute PYSGMCMCTrace (and possibly pymc3.MultiTrace from those) and \n",
    "# use those to compute e.g. ess and maybe produce some plots too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we also provide a shortcut function that directly computes a multitrace for one of our samplers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pymc3_multitrace in module pysgmcmc.diagnostics.sample_chains:\n",
      "\n",
      "pymc3_multitrace(get_sampler, n_chains=2, samples_per_chain=100, parameter_names=None)\n",
      "    Extract chains from `sampler` and return them as `pymc3.MultiTrace` object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    get_sampler : callable\n",
      "        A callable that takes a `tensorflow.Session` object as input\n",
      "        and returns a (possibly already burnt-in) instance of a\n",
      "        `pysgmcmc.sampling.MCMCSampler` subclass.\n",
      "    \n",
      "    parameter_names : List[String] or NoneType, optional\n",
      "        List of names for each target parameter of the sampler.\n",
      "        If set to `None`, simply enumerate the parameters and use those numbers\n",
      "        as names.\n",
      "        Defaults to `None`.\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    multitrace : pymc3.backends.base.MultiTrace\n",
      "        TODO: DOKU\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    ----------\n",
      "    TODO ADD EXAMPLE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pg.diagnostics.sample_chains.pymc3_multitrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PYSGMCMC - trained BNN\n",
    "\n",
    "We provide an implementation of a Bayesian Neural Network that is trained using our samplers. \n",
    "\n",
    "The (tensorflow-) architecture of this BNN can be customized by the user and any of our sampling methods can be used to sample networks during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGJPGrAgYY0wa+z/YsyO1J/L8HgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff1c6f9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pysgmcmc.diagnostics.objective_functions import sinc\n",
    "from pysgmcmc.models.bayesian_neural_network import BayesianNeuralNetwork, SamplingMethod\n",
    "\n",
    "\n",
    "## Set up data ##\n",
    "rng, n_datapoints = np.random.RandomState(np.random.randint(0, 10000)), 100\n",
    "X_train = np.array([rng.uniform(0., 1., 1) for _ in range(n_datapoints)])\n",
    "y_train = sinc(X_train)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)[:, None]\n",
    "y_test = sinc(X_test)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "session = tf.InteractiveSession(graph=g)\n",
    "with g.as_default():\n",
    "    model = BayesianNeuralNetwork(\n",
    "        session=session, batch_size=20, sampling_method=SamplingMethod.SGHMC,\n",
    "        learning_rate=np.sqrt(1e-4), mdecay=0.05, \n",
    "        burn_in_steps=3000, n_iters=50000, \n",
    "        normalize_input=True, normalize_output=True,\n",
    "    )\n",
    "    model.train(X_train, y_train)\n",
    "    prediction_mean, prediction_variance = model.predict(X_test)\n",
    "\n",
    "prediction_std = np.sqrt(prediction_variance)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(X_test[:, 0], y_test, label=\"true\", color=\"black\")\n",
    "plt.plot(X_train[:, 0], y_train, \"ro\")\n",
    "\n",
    "plt.plot(X_test[:, 0], prediction_mean, label=\"SGHMC\", color=\"blue\")\n",
    "plt.fill_between(X_test[:, 0], prediction_mean + prediction_std, prediction_mean - prediction_std, alpha=0.2, color=\"blue\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
